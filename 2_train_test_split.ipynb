{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('process_data/')\n",
    "\n",
    "import holidays\n",
    "us_holidays = holidays.UnitedStates()\n",
    "import libpysal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from util_data import generate_time_series\n",
    "from util_data import get_reference\n",
    "from setup import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 'before'\n",
    "max_lookback = 6\n",
    "predict_hzn = 1\n",
    "time_size = 4\n",
    "difference = True\n",
    "\n",
    "ref_period = 7 * (96//time_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.read_csv(data_dir+period+\"_dates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in ridership data\n",
    "rail = pd.read_csv(data_dir+\"data_processed/rail_catchment/\"+period+\"/rail_df.csv\")\n",
    "bus = pd.read_csv(data_dir+\"data_processed/rail_catchment/\"+period+\"/bus_rail_df.csv\")\n",
    "tnc = pd.read_csv(data_dir+\"data_processed/rail_catchment/\"+period+\"/tnc_rail_df.csv\")\n",
    "rail_los = pd.read_csv(data_dir+\"data_processed/rail_catchment/\"+period+\"/rail_count_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2582554\n",
      "1729777\n",
      "1947421\n"
     ]
    }
   ],
   "source": [
    "print(len(rail[['ts','station_id']].drop_duplicates()))\n",
    "print(len(bus[['ts','STATION_ID']].drop_duplicates()))\n",
    "print(len(tnc[['ts','STATION_ID']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ts', 'station_id', 'count'], dtype='object')\n",
      "Index(['STATION_ID', 'ts', 'bus_count'], dtype='object')\n",
      "Index(['STATION_ID', 'ts', 'tnc_count'], dtype='object')\n",
      "Index(['station_id', 'ts', 'num_schd_trp_15min', 'day_index'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rail.columns)\n",
    "print(bus.columns)\n",
    "print(tnc.columns)\n",
    "print(rail_los.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into one df\n",
    "df = pd.merge(rail, bus, how='left', left_on=['ts','station_id'], right_on=['ts','STATION_ID'])\n",
    "df = pd.merge(df, tnc, how='left', left_on=['ts','station_id'], right_on=['ts','STATION_ID'])\n",
    "df = pd.merge(df, rail_los, how='inner', left_on=['ts','station_id'], right_on=['ts','station_id'])\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "# temporal aggregation\n",
    "df['ts'] = df['ts'] // time_size\n",
    "df = df.groupby(['ts','station_id'], as_index=False).sum()\n",
    "\n",
    "# libpysal will automatically order stations in ascending order when reading adj matrix\n",
    "# sort to match\n",
    "df.sort_values(by=['ts','station_id'], inplace=True)\n",
    "\n",
    "# form vectors for train test split\n",
    "rail_pivot = pd.pivot_table(df, index='ts', columns='station_id', values='count', aggfunc=sum, fill_value=0)\n",
    "bus_pivot = pd.pivot_table(df, index='ts', columns='station_id', values='bus_count', aggfunc=sum, fill_value=0)\n",
    "tnc_pivot = pd.pivot_table(df, index='ts', columns='station_id', values='tnc_count', aggfunc=sum, fill_value=0)\n",
    "rail_los_pivot = pd.pivot_table(df, index='ts', columns='station_id', values='num_schd_trp_15min', aggfunc=sum, fill_value=0)\n",
    "\n",
    "station_id_list = rail_pivot.columns.tolist()\n",
    "print(len(station_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = rail_pivot.index.to_numpy()\n",
    "ts_hours = (timestamps % (96//time_size)) / time_size * 4\n",
    "mask = (ts_hours >=6) & (ts_hours <= 22)\n",
    "\n",
    "# generate time series data w.r.t. lookback and prediction horizon\n",
    "x, y, los, ts, ref = generate_time_series(data=[rail_pivot,bus_pivot,tnc_pivot], \n",
    "                                   targets=[rail_pivot], \n",
    "                                   others=[rail_los_pivot], \n",
    "                                   ts=timestamps,\n",
    "                                   offset=predict_hzn, \n",
    "                                   lookback=max_lookback,\n",
    "                                   ref_ts=ref_period,\n",
    "                                   difference=difference,\n",
    "                                   remove_list=timestamps[~mask].tolist())\n",
    "# there is only one target, others and reference\n",
    "y = y[0]\n",
    "los = los[0]\n",
    "ref = ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove holidays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process weather information\n",
    "ts_day = pd.DataFrame(ts // (96//time_size), columns=['DAY_INDEX'])\n",
    "\n",
    "weather = pd.read_csv(data_dir+\"data_processed/weather_\"+period+\".csv\")\n",
    "weather['TEMP_PCT_DIFF'] = np.abs((weather['TAVG'] - weather['TAVGAVG']) / weather['TAVGAVG'])\n",
    "weather['PRCP'] = weather['PRCP'] / weather['PRCP'].max()\n",
    "\n",
    "weather = pd.merge(ts_day, weather, on='DAY_INDEX') [['PRCP','TEMP_PCT_DIFF']].to_numpy()\n",
    "assert len(weather) == len(ts_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "test_size = 0.10\n",
    "x_train, x_test, y_train, y_test, ts_train, ts_test, ref_train, ref_test, los_train, los_test, w_train, w_test = \\\n",
    "        train_test_split(x, y, ts, ref, los, weather, test_size=test_size, shuffle=False)\n",
    "n_stations = x_train.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# val test split\n",
    "val_test_split = 0.5\n",
    "x_val, x_test, y_val, y_test, ts_val, ts_test, ref_val, ref_test, los_val, los_test, w_val, w_test = \\\n",
    "        train_test_split(x_test, y_test, ts_test, ref_test, los_test, w_test, \n",
    "                         test_size=val_test_split, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if difference:\n",
    "    differenced = \"diff\"\n",
    "else:\n",
    "    differenced = \"raw\"\n",
    "\n",
    "with open(data_dir+\"data_processed/rail_catchment/\"+period+\"/\"+\n",
    "          period+\"_\"+str(predict_hzn)+\"_\"+str(time_size)+\"_\"+differenced+\"_data_train.pkl\",\"wb\") as f:\n",
    "    pkl.dump(x_train, f)\n",
    "    pkl.dump(ref_train,f)\n",
    "    pkl.dump(los_train, f)\n",
    "    pkl.dump(w_train, f)\n",
    "    pkl.dump(y_train, f)\n",
    "    pkl.dump(ts_train, f)\n",
    "    pkl.dump(station_id_list, f)\n",
    "    \n",
    "with open(data_dir+\"data_processed/rail_catchment/\"+period+\"/\"+\n",
    "          period+\"_\"+str(predict_hzn)+\"_\"+str(time_size)+\"_\"+differenced+\"_data_val.pkl\",\"wb\") as f:\n",
    "    pkl.dump(x_val, f)\n",
    "    pkl.dump(ref_val,f)\n",
    "    pkl.dump(los_val, f)\n",
    "    pkl.dump(w_val, f)\n",
    "    pkl.dump(y_val, f)\n",
    "    pkl.dump(ts_val, f)\n",
    "    pkl.dump(station_id_list, f)\n",
    "    \n",
    "with open(data_dir+\"data_processed/rail_catchment/\"+period+\"/\"+\n",
    "          period+\"_\"+str(predict_hzn)+\"_\"+str(time_size)+\"_\"+differenced+\"_data_test.pkl\",\"wb\") as f:\n",
    "    pkl.dump(x_test, f)\n",
    "    pkl.dump(ref_test,f)\n",
    "    pkl.dump(los_test, f)\n",
    "    pkl.dump(w_test, f)\n",
    "    pkl.dump(y_test, f)\n",
    "    pkl.dump(ts_test, f)\n",
    "    pkl.dump(station_id_list, f)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
