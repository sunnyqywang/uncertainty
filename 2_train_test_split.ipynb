{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('process_data/')\n",
    "\n",
    "import holidays\n",
    "us_holidays = holidays.UnitedStates()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from util_data import generate_time_series\n",
    "from util_data import get_reference\n",
    "from setup import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lookback = 6\n",
    "predict_hzn = 1\n",
    "difference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"rail_catchment\"\n",
    "if dataset == \"census_tract\":\n",
    "    spatial_identifier = 'GEOID10'\n",
    "    main_var = 'tnc'\n",
    "if dataset == \"rail_catchment\":\n",
    "    spatial_identifier = 'station_id'\n",
    "    main_var = 'rail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = [(name[-17:-11], name[-10:-4], name.split(\"_\")[0], name) for name in os.listdir(project_data_dir+\"data_processed/\"+dataset+\"/\") if name[-4:]=='.csv']\n",
    "files = pd.DataFrame(files, columns=['start_date','end_date','mode','name'])\n",
    "files['start_date'] = pd.to_datetime(files['start_date'], format=\"%y%m%d\")\n",
    "files['end_date'] = pd.to_datetime(files['end_date'], format=\"%y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_files(data_dir, files, start_date, end_date, date_col, preprocess=None):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for s,e,name in zip(files['start_date'],files['end_date'],files['name']):  \n",
    "        if (end_date >= s) & (start_date <= e):\n",
    "            df_chunk = pd.read_csv(data_dir+name)\n",
    "            if preprocess is not None: \n",
    "                df_chunk = preprocess(df_chunk)\n",
    "            if (end_date >= e) & (start_date <= s):\n",
    "                print(name, 'all')\n",
    "                df = pd.concat([df,df_chunk])\n",
    "            else:\n",
    "                print(name, 'part')\n",
    "                df_chunk[date_col] = pd.to_datetime(df_chunk[date_col]).dt.date\n",
    "                df = pd.concat([df,df_chunk[(df_chunk[date_col]>=start_date)&(df_chunk[date_col]<=end_date)]])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_size = 1\n",
    "ref_period = 7 * (96//time_size)\n",
    "\n",
    "# start_date = pd.to_datetime('20190801').date()\n",
    "# end_date = pd.to_datetime('20200301').date()\n",
    "\n",
    "# start_date = pd.to_datetime('20200316').date()\n",
    "# end_date = pd.to_datetime('20201017').date()\n",
    "\n",
    "# start_date = pd.to_datetime('20200302')\n",
    "# end_date = pd.to_datetime('20200315')\n",
    "\n",
    "# start_date = pd.to_datetime('20200316')\n",
    "# end_date = pd.to_datetime('20200329')\n",
    "\n",
    "start_date = pd.to_datetime('20200622')\n",
    "end_date = pd.to_datetime('20200705')\n",
    "\n",
    "# start_date = pd.to_datetime('20200608')\n",
    "# end_date = pd.to_datetime('20200621')\n",
    "\n",
    "# start_date = pd.to_datetime('20201012')\n",
    "# end_date = pd.to_datetime('20201025')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rail_df_200316_201031.csv part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rail ['ts', 'day', 'quarter_hour', 'station_id', 'count']\n",
      "bus_rail_df_200316_201031.csv part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus ['station_id', 'ts', 'day', 'quarter_hour', 'bus_count']\n",
      "tnc_rail_df_200316_201031.csv part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tnc ['station_id', 'ts', 'day', 'quarter_hour', 'tnc_count']\n",
      "los_df_200316_201031.csv part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los ['station_id', 'day', 'quarter_hour', 'ts', 'num_schd_trp_15min', 'day_index']\n"
     ]
    }
   ],
   "source": [
    "start_date = start_date - pd.Timedelta(7, \"d\")\n",
    "\n",
    "data = {}\n",
    "for mode in ['rail','bus','tnc','los']:\n",
    "    data[mode] = stitch_files(project_data_dir+\"data_processed/\"+dataset+\"/\", files[files['mode']==mode], start_date, end_date, \"day\")\n",
    "    print(mode, data[mode].columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-06-22 00:00:00')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = start_date + pd.Timedelta(7, \"d\")\n",
    "\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_list = ['tnc','los','rail','bus']\n",
    "var_list.remove(main_var)\n",
    "\n",
    "df = data[main_var]\n",
    "for mode in var_list:\n",
    "#     df = pd.merge(df, data[mode], how='left', on=['ts','day','day_index','quarter_hour']+[spatial_identifier])\n",
    "    df = pd.merge(df, data[mode], how='left', on=['ts','day','quarter_hour']+[spatial_identifier])\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# temporal aggregation\n",
    "df['ts'] = df['ts'] // time_size\n",
    "df = df.groupby(['ts','day','quarter_hour']+[spatial_identifier], as_index=False).sum()\n",
    "\n",
    "if dataset == 'census_tract':\n",
    "    with open(project_dir+\"data/data_processed/select_tracts.pkl\", \"rb\") as f:\n",
    "        common_stations = pkl.load(f)\n",
    "else:\n",
    "    with open(project_dir+\"data/data_processed/common_stations.pkl\", \"rb\") as f:\n",
    "        common_stations = pkl.load(f)\n",
    "        \n",
    "df = df[df[spatial_identifier].isin(common_stations)]\n",
    "\n",
    "# libpysal will automatically order stations in ascending order when reading adj matrix\n",
    "# sort to match\n",
    "df.sort_values(by=['ts']+[spatial_identifier], inplace=True)\n",
    "\n",
    "# form vectors for train test split\n",
    "\n",
    "df_pivots = {\n",
    "    'rail': pd.pivot_table(df, index='ts', columns=spatial_identifier, values='count', aggfunc=sum, fill_value=0),\n",
    "    'bus': pd.pivot_table(df, index='ts', columns=spatial_identifier, values='bus_count', aggfunc=sum, fill_value=0),\n",
    "    'tnc': pd.pivot_table(df, index='ts', columns=spatial_identifier, values='tnc_count', aggfunc=sum, fill_value=0),\n",
    "    'los': pd.pivot_table(df, index='ts', columns=spatial_identifier, values='num_schd_trp_15min', aggfunc=sum, fill_value=0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = df_pivots[main_var].index.to_numpy()\n",
    "ts_hours = (timestamps % (96//time_size)) / (4/time_size)\n",
    "if dataset == 'rail_catchment':\n",
    "    mask = (ts_hours >=6) & (ts_hours <= 22)\n",
    "    order = ['rail','bus','tnc']\n",
    "else:\n",
    "    mask = (ts_hours < 3) | (ts_hours >= 8)    \n",
    "    order = ['tnc','rail','bus']\n",
    "    \n",
    "# generate time series data w.r.t. lookback and prediction horizon\n",
    "x, y, los, ts, ref = generate_time_series(data=[df_pivots[v] for v in order], \n",
    "                                   targets=[df_pivots[main_var]], \n",
    "                                   others=[df_pivots['los']], \n",
    "                                   ts=timestamps,\n",
    "                                   offset=predict_hzn, \n",
    "                                   lookback=max_lookback,\n",
    "                                   ref_ts=ref_period,\n",
    "                                   difference=difference,\n",
    "                                   remove_list=timestamps[~mask].tolist())\n",
    "# there is only one target, others and reference\n",
    "y = y[0]\n",
    "los = los[0]\n",
    "ref = ref[0]\n",
    "# Remove holidays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather_200316_201031.csv part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/envs/qingyi/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    }
   ],
   "source": [
    "weather = stitch_files(project_data_dir+\"data_processed/\"+dataset+\"/\", files[files['mode']=='weather'], start_date, end_date, \"DATE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process weather information\n",
    "ts_day = pd.DataFrame(ts // (96//time_size), columns=['DAY_INDEX'])\n",
    "\n",
    "# weather = pd.read_csv(data_dir+\"data_processed/weather_\"+start_date.strftime(\"%y%m%d\")+'_'+end_date.strftime(\"%y%m%d\")+'.csv'.csv\")\n",
    "weather['TEMP_PCT_DIFF'] = np.abs((weather['TAVG'] - weather['TAVGAVG']) / weather['TAVGAVG'])\n",
    "weather['PRCP'] = weather['PRCP'] / weather['PRCP'].max()\n",
    "\n",
    "weather = pd.merge(ts_day, weather, on='DAY_INDEX', how='left') [['PRCP','TEMP_PCT_DIFF']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if difference:\n",
    "    differenced = \"diff\"\n",
    "else:\n",
    "    differenced = \"raw\"\n",
    "\n",
    "with open(data_dir+\"data_processed/\"+dataset+\"/\"+start_date.strftime(\"%y%m%d\")+'_'+end_date.strftime(\"%y%m%d\")+\"_\"+\n",
    "          str(predict_hzn)+\"_\"+str(time_size)+\"_\"+differenced+\".pkl\",\"wb\") as f:\n",
    "    pkl.dump(x, f)\n",
    "    pkl.dump(ref,f)\n",
    "    pkl.dump(los, f)\n",
    "    pkl.dump(weather, f)\n",
    "    pkl.dump(y, f)\n",
    "    pkl.dump(ts, f)\n",
    "    pkl.dump(common_stations, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this when time period is 20190801 - 20200301\n",
    "### to get selected 59 TNC census tracts.\n",
    "### Criterion: having more than 30 trips/h pre-COVID\n",
    "\n",
    "all_tracts = tnc_pivot.columns.to_numpy()\n",
    "\n",
    "reselect = all_tracts[tnc_pivot.mean()>7.5]\n",
    "\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "# shapefile of census blocks 2010 \n",
    "gblk = pd.read_csv(data_dir+'data_raw/CensusBlockTIGER2010.csv')\n",
    "# craete a geometric object\n",
    "gblk['the_geom'] = gblk['the_geom'].apply(wkt.loads)\n",
    "# create the geo dataframe\n",
    "block_gdf = gpd.GeoDataFrame(gblk, geometry='the_geom')\n",
    "# Calculate the area of the blocks/polygons\n",
    "block_gdf.crs = CRS('epsg:4326')\n",
    "block_gdf = block_gdf.to_crs(\"epsg:26916\")\n",
    "\n",
    "tract_gdf = block_gdf.dissolve(by=['STATEFP10','COUNTYFP10','TRACTCE10'], \n",
    "                               as_index=False)[['STATEFP10','COUNTYFP10','TRACTCE10','the_geom']]\n",
    "tract_gdf['area'] = tract_gdf['the_geom'].map(lambda p:p.area)\n",
    "tract_gdf['GEOID10'] = tract_gdf['STATEFP10'].astype(str)+\"_\"+tract_gdf['COUNTYFP10'].astype(str)+\"_\"+tract_gdf['TRACTCE10'].astype(str)\n",
    "\n",
    "tract_gdf[tract_gdf['GEOID10'].isin(reselect)].plot()\n",
    "\n",
    "with open(project_dir+\"data/data_processed/select_tracts.pkl\", \"wb\") as f:\n",
    "    pkl.dump(list(reselect), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qingyi",
   "language": "python",
   "name": "qingyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
